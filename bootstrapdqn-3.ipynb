{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğŸ“‹ **Student Information**","metadata":{"id":"20e54f37"}},{"cell_type":"markdown","source":"*Complete the required fields below with your personal and W&B account details.*","metadata":{"id":"cf66003f"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"WANDB_API_KEY\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nprint(secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:40.735506Z","iopub.execute_input":"2025-06-08T12:11:40.735710Z","iopub.status.idle":"2025-06-08T12:11:40.870944Z","shell.execute_reply.started":"2025-06-08T12:11:40.735693Z","shell.execute_reply":"2025-06-08T12:11:40.870141Z"}},"outputs":[{"name":"stdout","text":"1940b11d1a8dd3b2fd752c6599025c5128ac0877\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"FIRST_NAME = \"Mohammadjavad\" # replace with your first name\nLAST_NAME = \"Ahmadpour\" # replace with your last name\nSTUDENT_ID = 400104697 # replace with your student id\nWANDB_ID = \"mohamadahmadpour1383\" # replace with your wandb username\nPROJECT_NAME = f\"{FIRST_NAME}-{LAST_NAME}-DQN-EXPLORE-HW\"\nprint(f\"Project name: {PROJECT_NAME}\")","metadata":{"id":"db7121c9","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:40.872673Z","iopub.execute_input":"2025-06-08T12:11:40.872886Z","iopub.status.idle":"2025-06-08T12:11:40.877450Z","shell.execute_reply.started":"2025-06-08T12:11:40.872869Z","shell.execute_reply":"2025-06-08T12:11:40.876600Z"}},"outputs":[{"name":"stdout","text":"Project name: Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(f\"Check my results at https://wandb.ai/{WANDB_ID}/{PROJECT_NAME}\")","metadata":{"id":"18618b3a","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:40.878080Z","iopub.execute_input":"2025-06-08T12:11:40.878312Z","iopub.status.idle":"2025-06-08T12:11:40.895804Z","shell.execute_reply.started":"2025-06-08T12:11:40.878292Z","shell.execute_reply":"2025-06-08T12:11:40.895035Z"}},"outputs":[{"name":"stdout","text":"Check my results at https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Set DEBUG to True if you are still implementing the code and debugging\n# and don't want to make your wandb dashboard messy.\n# set DEBUG to False if you are almost done with the implementation\n# and want check performance and compare hyperparameters and models\nDEBUG = False","metadata":{"id":"3c3c2da0","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:40.896708Z","iopub.execute_input":"2025-06-08T12:11:40.896943Z","iopub.status.idle":"2025-06-08T12:11:40.913312Z","shell.execute_reply.started":"2025-06-08T12:11:40.896927Z","shell.execute_reply":"2025-06-08T12:11:40.912623Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# ğŸ“˜ Guidelines\n\n> âš ï¸ **Please read this section carefully before proceeding.**","metadata":{"id":"f15a1380"}},{"cell_type":"markdown","source":"### ğŸ”§ Install Dependencies","metadata":{"id":"12dbfb80"}},{"cell_type":"code","source":"!apt install build-essential python3-dev\n!git clone https://github.com/DeepRLCourse/Homework-10.git\n%pip install swig\n%pip install \"Homework-10/BootstrapDQN\"","metadata":{"id":"5a00e8aa","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:11:40.914054Z","iopub.execute_input":"2025-06-08T12:11:40.914299Z","iopub.status.idle":"2025-06-08T12:14:08.168719Z","shell.execute_reply.started":"2025-06-08T12:11:40.914279Z","shell.execute_reply":"2025-06-08T12:14:08.167811Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nbuild-essential is already the newest version (12.9ubuntu3).\npython3-dev is already the newest version (3.10.6-1~22.04.1).\npython3-dev set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\nCloning into 'Homework-10'...\nremote: Enumerating objects: 111, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (67/67), done.\u001b[K\nremote: Total 111 (delta 37), reused 108 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (111/111), 1.14 MiB | 8.83 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nCollecting swig\n  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\nDownloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: swig\nSuccessfully installed swig-4.3.1\nNote: you may need to restart the kernel to use updated packages.\nProcessing ./Homework-10/BootstrapDQN\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ale-py<=0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.10.2)\nCollecting dotenv>=0.9.9 (from main==0.1.0)\n  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\nCollecting gymnasium>=1.1.1 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting ipykernel>=6.29.5 (from main==0.1.0)\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (5.10.4)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (1.26.4)\nCollecting pip>=25.0.1 (from main==0.1.0)\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: swig>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (4.3.1)\nRequirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (2.6.0+cu124)\nRequirement already satisfied: wandb>=0.19.9 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.19.9)\nCollecting python-dotenv (from dotenv>=0.9.9->main==0.1.0)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (4.13.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (0.0.4)\nCollecting box2d-py==2.3.5 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (2.6.1)\nRequirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.8.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (8.6.3)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.6.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.0.0)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (6.4.2)\nRequirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.1)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (4.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->main==0.1.0) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (75.2.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.19.9->main==0.1.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (4.0.12)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.24.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.5->main==0.1.0) (2.9.0.post0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->main==0.1.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->main==0.1.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.13)\nDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\nDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: main, box2d-py\n  Building wheel for main (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for main: filename=main-0.1.0-py3-none-any.whl size=11117 sha256=b9d41c0024f58e51a1cb8d905d311e9557d12ece007f2bf45698b4306ca90e38\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3vzvr7dn/wheels/4f/16/b7/f0afc1a4a4574831edbabf07feb162c98e9e62978951f878e1\n  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379374 sha256=b4b0bf982e30716c0b8b55b0120d6a49735dff04f6586b0526964ade8efeb181\n  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\nSuccessfully built main box2d-py\nInstalling collected packages: box2d-py, python-dotenv, pip, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dotenv, nvidia-cusolver-cu12, ipykernel, gymnasium, main\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: ipykernel\n    Found existing installation: ipykernel 6.17.1\n    Uninstalling ipykernel-6.17.1:\n      Successfully uninstalled ipykernel-6.17.1\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.1.1 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.1.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed box2d-py-2.3.5 dotenv-0.9.9 gymnasium-1.1.1 ipykernel-6.29.5 main-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pip-25.1.1 python-dotenv-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### ğŸ“Š Weights & Biases (W&B) Integration","metadata":{"id":"2da9f086"}},{"cell_type":"markdown","source":"Follow these steps to set up tracking with [Weights & Biases](https://wandb.ai/site/):\n\n1. [Create a W&B account](https://wandb.ai/site/).\n2. Set the `WANDB_ID` variable in the **Student Information** section to your W&B username.\n3. Create a new project using the name defined in the `PROJECT_NAME` variable. Ensure the project visibility is set to **Public**.\n4. [Retrieve your W&B API key](https://docs.wandb.ai/support/find_api_key/).\n5. Set the `WANDB_API_KEY`:\n   - As a **secret** if you're using **Google Colab** or **Kaggle**\n   - As an **environment variable** if running locally","metadata":{"id":"693ee7d0"}},{"cell_type":"markdown","source":"#### ğŸ’» Platform-Specific Setup","metadata":{"id":"f1df8b34"}},{"cell_type":"markdown","source":"##### Google Colab","metadata":{"id":"b3d17516"}},{"cell_type":"markdown","source":"#### Kaggle","metadata":{"id":"8f7a799d"}},{"cell_type":"markdown","source":"To configure W&B API key in Kaggle:\n\n- Go to: `Add-ons` â†’ `Secrets` â†’ `Add Secret`\n- **Label:** `WANDB_API_KEY`  \n- **Value:** `<your_api_key>`\n\n> You only need to add the secret â€” no code changes are required.","metadata":{"id":"83978813"}},{"cell_type":"markdown","source":"#### Local","metadata":{"id":"f891bcc4"}},{"cell_type":"markdown","source":"You can set the `WANDB_API_KEY` as an environment variable manually or,\n\nstore it in a `.env` file:\n```bash\n# secrets.env\nWANDB_API_KEY=your_api_key\n```\nand then run the following cell:","metadata":{"id":"d5a546a1"}},{"cell_type":"code","source":"from bootstrapdqn import get_machine\nif get_machine() == \"Local Machine\":\n    import dotenv\n    dotenv.load_dotenv(\".workspace/secrets.env\") # give it the path to your secrets.env file","metadata":{"id":"053fb72c","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:08.169925Z","iopub.execute_input":"2025-06-08T12:14:08.170269Z","iopub.status.idle":"2025-06-08T12:14:14.100556Z","shell.execute_reply.started":"2025-06-08T12:14:08.170231Z","shell.execute_reply":"2025-06-08T12:14:14.099727Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### ğŸ“¤ Submission Requirements","metadata":{"id":"a1b0cfb6"}},{"cell_type":"markdown","source":"In addition to submitting this notebook on **Quera**, you must:\n\n- Have a W&B project matching the name in `PROJECT_NAME`, under the account defined by `WANDB_ID`\n- Ensure the W&B link displayed in the **Student Information** section is valid\n- Tag your final experiment run for **each algorithm** with `Final`:\n  - Go to **Runs** (left sidebar) â†’ **Tags** â†’ Add the tag `Final`\n  - A total of **four** runs should be tagged as `Final`\n\nâš ï¸ **Important:** The `save_code` option must remain enabled. If a `Final` run does not include saved code, it will **not** be graded.","metadata":{"id":"24a2369d"}},{"cell_type":"markdown","source":"### ğŸ§® Grading Criteria","metadata":{"id":"954cfcea"}},{"cell_type":"markdown","source":"The score for each algorithm is provided in its respective section. This score is then multiplied by the environment score:\n- `CartPole`: Ã— 0.1\n    - Minimum requirement: over 200 points across 5 consecutive evaluations\n- `LunarLander`: Ã— 0.7\n    - Minimum requirement: over 200 points across 5 consecutive evaluations\n- `MountainCar`: Ã— 1.0\n    - Minimum requirement: reach the goal state across 5 consecutive evaluations\n- `FrozenLake`: Ã— 1.2\n    - Minimum requirement: reach the goal state across at least 5 evaluations of 15 consecutive evaluations\n- `SeaQuest`: Ã— 1.5\n    -  Minimum requirement: over 2000 points across 5 consecutive evaluations\n\nTotal Score is 100. you can get up to 80 bonus score (180)","metadata":{"id":"790fcef8"}},{"cell_type":"markdown","source":"### ğŸ“ Implementation Guide","metadata":{"id":"3041fb4e"}},{"cell_type":"markdown","source":"- Implement the algorithms as subclasses of `BaseDQNAgent` provided in [`base_agent.py`](https://github.com/DeepRLCourse/Homework-10/blob/main/BootstrapDQN/src/bootstrapdqn/base_agent.py). You may add or override methods/properties as needed.\n    - The `BaseDQNAgent` code will be automatically downloaded and imported. Ensure you review it carefully before implementing your algorithms.\n- Code blocks or lines marked with `# DO NOT CHANGE` must remain unaltered in your final submission. You may modify them during development for debugging purposes, but revert them before submitting.\n- If running locally, real-time W&B logging might face restrictions. Use W&B's offline mode for experiments and sync them later using the `wandb sync` command ([link](https://docs.wandb.ai/support/run_wandb_offline/)).\n- Prioritize vector operations over loops for better performance. While algorithm descriptions might use loops for clarity, only the main training and rollout loops (implemented in `BaseDQNAgent`) should remain iterative. Failure to vectorize may significantly increase convergence time.\n- For potentially more stable and faster training, you may consider using *Smooth L1 Loss* instead of Mean Squared Error. (Optional)\n- Weight initialization significantly impacts performance. Orthogonal initialization is generally recommended in the RL community and might be worth trying.\n","metadata":{"id":"4881fc69"}},{"cell_type":"markdown","source":"### ğŸ’¡ Tips & More","metadata":{"id":"e2b9764f"}},{"cell_type":"markdown","source":"The following resource provides general advice for implementing and debugging RL algorithms (not required for this homework, but highly recommended):\n\n- [Debugging RL, Without the Agonizing Pain](https://andyljones.com/posts/rl-debugging.html)","metadata":{"id":"df839956"}},{"cell_type":"markdown","source":"# ğŸ§­ Exploration Techniques in DQN","metadata":{"id":"9109e855"}},{"cell_type":"markdown","source":"## ğŸš€ Initialization\n","metadata":{"id":"a0fe53f9"}},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nfrom bootstrapdqn import ReplayBuffer, BaseDQNAgent, get_machine, set_wandb_key_form_secrets, envs\nimport torch\nfrom torch import nn\nimport wandb\nimport random\nimport gymnasium as gym\nimport ale_py\n\ngym.register_envs(ale_py)","metadata":{"id":"6582172e","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:14.102918Z","iopub.execute_input":"2025-06-08T12:14:14.103300Z","iopub.status.idle":"2025-06-08T12:14:14.200573Z","shell.execute_reply.started":"2025-06-08T12:14:14.103281Z","shell.execute_reply":"2025-06-08T12:14:14.200023Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nTA = True if WANDB_ID == \"alireza9\" else False\nSAVE_CODE = False if TA else True","metadata":{"id":"18ca1cc8","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:14.201207Z","iopub.execute_input":"2025-06-08T12:14:14.201397Z","iopub.status.idle":"2025-06-08T12:14:15.428413Z","shell.execute_reply.started":"2025-06-08T12:14:14.201380Z","shell.execute_reply":"2025-06-08T12:14:15.427580Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\n# IF YOU CHANGE ANYTHING ABOUT ENVIRONMENTS AND THEIR RUN CONFIGS, YOUR CODE WILL NOT BE GRADED\nfrom pprint import pprint\nENVS = envs()\npprint(ENVS)","metadata":{"id":"2621aaaa","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.429299Z","iopub.execute_input":"2025-06-08T12:14:15.429563Z","iopub.status.idle":"2025-06-08T12:14:15.443752Z","shell.execute_reply.started":"2025-06-08T12:14:15.429541Z","shell.execute_reply":"2025-06-08T12:14:15.443033Z"}},"outputs":[{"name":"stdout","text":"{'CartPole': {'env': {'env_config': {}, 'env_name': 'CartPole-v1', 'seed': 43},\n              'run': {'max_episodes': 1000,\n                      'max_steps': 50000,\n                      'max_steps_per_episode': 100000,\n                      'max_time': 720.0}},\n 'FrozenLake': {'env': {'env_config': {'p': 0.87, 'size': 14},\n                        'env_name': 'FrozenLake-v1',\n                        'seed': 42},\n                'run': {'max_episodes': 1000000,\n                        'max_steps': 1000000,\n                        'max_steps_per_episode': 100000,\n                        'max_time': 14400}},\n 'LunarLander': {'env': {'env_config': {},\n                         'env_name': 'LunarLander-v3',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 200000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 7200}},\n 'MountainCar': {'env': {'env_config': {},\n                         'env_name': 'MountainCar-v0',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 300000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 9000.0}},\n 'SeaQuest': {'env': {'env_config': {},\n                      'env_name': 'Seaquest-ramNoFrameskip-v4',\n                      'seed': 43},\n              'run': {'max_episodes': 1000000,\n                      'max_steps': 2000000,\n                      'max_steps_per_episode': 1000000,\n                      'max_time': 28800}}}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"if not DEBUG:\n    set_wandb_key_form_secrets()","metadata":{"id":"7d95b847","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.444608Z","iopub.execute_input":"2025-06-08T12:14:15.445193Z","iopub.status.idle":"2025-06-08T12:14:15.530582Z","shell.execute_reply.started":"2025-06-08T12:14:15.445152Z","shell.execute_reply":"2025-06-08T12:14:15.530069Z"}},"outputs":[{"name":"stdout","text":"your machine is detected as Kaggle\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## ğŸ’» Algorithms Implementation","metadata":{"id":"4a509ba1"}},{"cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{"id":"20d1d916"}},{"cell_type":"markdown","source":"Consider the following implementation as a reference for implementing other algorithms.\n\nYou can also use it as a baseline for comparing the performance of subsequent algorithms.","metadata":{"id":"a14b7977"}},{"cell_type":"code","source":"class EpsGreedyDQNAgent(BaseDQNAgent):\n    \"\"\"\n    Epsilon-greedy DQN agent.\n    \"\"\"\n\n    def __init__(self, epsilon: float = 0.1, eps_decay: float = 0.999, eps_min: float = 0.01, **kwargs):\n        super().__init__(**kwargs)\n        self.epsilon = epsilon\n        self.eps_decay = eps_decay\n        self.eps_min = eps_min\n\n    def _decay_eps(self):\n        \"\"\"\n        Decay the epsilon value.\n        \"\"\"\n        self.epsilon = max(self.epsilon * self.eps_decay, self.eps_min)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _create_network(self):\n        self.q_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n        self.q_network.apply(\n            lambda m: torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n            if isinstance(m, nn.Linear)\n            else None\n        )\n        self.target_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n\n    def _compute_loss(self, batch):\n        \"\"\"\n        Compute the loss for the DQN agent.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n\n        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n        next_q_values = self.target_network(next_states).max(1)[0]\n        expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n\n        loss = nn.SmoothL1Loss()(q_values, expected_q_values)\n        return loss\n\n    def _act_in_training(self, state):\n        \"\"\"\n        Select an action during training.\n        \"\"\"\n        self._decay_eps()\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample()\n        else:\n            with torch.no_grad():\n                q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n                return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        \"\"\"\n        Select an action during evaluation.\n        \"\"\"\n        with torch.no_grad():\n            q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n            return q_values.argmax().item()\n\n    def _wandb_train_step_dict(self):\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"train_step/epsilon\"] = self.epsilon\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"epsilon\"] = self.epsilon\n        save_dict[\"eps_decay\"] = self.eps_decay\n        save_dict[\"eps_min\"] = self.eps_min\n        return save_dict\n","metadata":{"id":"65d5990e","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.531158Z","iopub.execute_input":"2025-06-08T12:14:15.531354Z","iopub.status.idle":"2025-06-08T12:14:15.542596Z","shell.execute_reply.started":"2025-06-08T12:14:15.531340Z","shell.execute_reply":"2025-06-08T12:14:15.542025Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Bootstrap DQN","metadata":{"id":"5cff8451"}},{"cell_type":"markdown","source":"> Paper: [Deep Exploration via Bootstrapped DQN](https://arxiv.org/abs/1602.04621)\n\n**40 Points**","metadata":{"id":"49e4fe6f"}},{"cell_type":"markdown","source":"#### Details\n\nIn this algorithm, instead of using a single network, we maintain an ensemble of networks (or a single network with multiple heads). At the start of each training episode, we randomly select one of these networks (heads) and use it to choose actions for the entire episode. This strategy approximates Thompson Sampling for the K-armed Bandit problem, enabling deeper exploration by leveraging the diversity among the ensemble members.","metadata":{"id":"c2711c55"}},{"cell_type":"markdown","source":"#### Implementation","metadata":{"id":"18fd3757"}},{"cell_type":"code","source":"class MultiHeadQNet(nn.Module):\n    \"\"\"\n    Multi-head Q-network for Bootstrap DQN.\n    Shares the feature extractor and has k independent output heads.\n    \"\"\"\n    def __init__(self, obs_dim: int, action_dim: int, num_heads: int):\n        super().__init__()\n        self.num_heads = num_heads\n\n        # Shared feature extractor\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(obs_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n        )\n\n        # K independent output heads\n        self.heads = nn.ModuleList([\n            nn.Linear(256, action_dim) for _ in range(num_heads)\n        ])\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        \"\"\"\n        Initialize weights of the network.\n        \"\"\"\n        for m in self.feature_extractor:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n                if m.bias is not None:\n                    torch.nn.init.constant_(m.bias, 0)\n        for head in self.heads:\n            if isinstance(head, nn.Linear):\n                torch.nn.init.orthogonal_(head.weight) # Default gain for linear\n                if head.bias is not None:\n                    torch.nn.init.constant_(head.bias, 0)\n\n    def forward(self, x: torch.Tensor):\n        \"\"\"\n        Forward pass through the network.\n        Returns Q-values for all heads.\n        Input x: (batch_size, obs_dim)\n        Output: (batch_size, num_heads, action_dim)\n        \"\"\"\n        features = self.feature_extractor(x)\n        q_values_per_head = []\n        for head in self.heads:\n            q_values_per_head.append(head(features))\n        # Stack the results: list of (batch_size, action_dim) -> (batch_size, num_heads, action_dim)\n        return torch.stack(q_values_per_head, dim=1)\n\n\nclass BootstrapDQNAgent(EpsGreedyDQNAgent):\n    \"\"\"\n    Bootstrap DQN agent.\n    \"\"\"\n\n    def __init__(self, k: int = 10, bernoulli_p: float = 0.5, **kwargs):\n        self.k = k\n        super().__init__(**kwargs)\n        self.bernoulli_p = bernoulli_p\n        self.bernoulli_dist = torch.distributions.Bernoulli(probs=torch.tensor([self.bernoulli_p]).to(self.device))\n        self.current_head = 0 # This will be sampled at the start of each episode\n\n    def _create_network(self):\n        self.q_network = MultiHeadQNet(\n            self.env.observation_space.shape[0],\n            self.env.action_space.n,\n            self.k\n        ).to(self.device)\n\n        self.target_network = MultiHeadQNet(\n            self.env.observation_space.shape[0],\n            self.env.action_space.n,\n            self.k\n        ).to(self.device)\n        self.target_network.load_state_dict(self.q_network.state_dict()) # Initialize target network\n\n    def _create_replay_buffer(self, max_size=1000000):\n        # Add 'mask' to the replay buffer schema\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n                (\"mask\", (self.k,), torch.float32), # Mask for each head\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _preprocess_add(self, state, action, reward, next_state, done):\n        \"\"\"\n        Generates k Bernoulli masks and converts all transition data\n        to torch tensors, moving them to the agent's device.\n        \"\"\"\n        mask = self.bernoulli_dist.sample((self.k,)).squeeze(-1).to(self.device) # Shape (k,)\n\n        state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n        action_tensor = torch.tensor(action, dtype=torch.int64, device=self.device)\n        reward_tensor = torch.tensor(reward, dtype=torch.float32, device=self.device)\n        next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n        # 'done' needs to be float32 for (1 - dones) multiplication in loss calculation\n        done_tensor = torch.tensor(done, dtype=torch.float32, device=self.device)\n\n        return dict(state=state_tensor, action=action_tensor, reward=reward_tensor,\n                    next_state=next_state_tensor, done=done_tensor, mask=mask)\n\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"] # Shape (batch_size, k)\n\n        # Q-values from the main Q-network (batch_size, k, action_dim)\n        all_q_values = self.q_network(states)\n        # Target Q-values from the target network (batch_size, k, action_dim)\n        with torch.no_grad():\n            all_target_q_values = self.target_network(next_states)\n            max_next_q_values = all_target_q_values.max(dim=2)[0] # Max Q-value for each head (batch_size, k)\n            expected_q_values_per_head = rewards.unsqueeze(1) + (1 - dones.unsqueeze(1)) * self.gamma * max_next_q_values # (batch_size, k)\n\n        total_loss = 0.0\n        # Iterate over each head to compute masked loss\n        for i in range(self.k):\n            # Select Q-values for the action taken for the current head i\n            q_values_for_head_i = all_q_values[:, i, :].gather(1, actions.unsqueeze(1)).squeeze() # (batch_size,)\n            \n            # Select the corresponding expected Q-values for head i\n            expected_q_values_for_head_i = expected_q_values_per_head[:, i] # (batch_size,)\n            \n            # Compute SmoothL1Loss for this head (reduction='none' to apply mask)\n            loss_for_head_i = nn.SmoothL1Loss(reduction='none')(q_values_for_head_i, expected_q_values_for_head_i)\n            \n            # Apply the mask for head i and sum up the masked loss\n            # Only transitions where mask[i] is 1 contribute to this head's loss\n            masked_loss_for_head_i = loss_for_head_i * masks[:, i]\n            \n            # Add the mean of the masked loss for this head to total loss\n            # We take mean of masked loss to avoid issues with varying number of active samples.\n            # If all masks are 0, mean will be 0.\n            if masked_loss_for_head_i.sum() > 0: # Avoid division by zero if all masks are zero for this head\n                total_loss += masked_loss_for_head_i.sum() / masks[:, i].sum()\n            \n        # Average the total loss across all heads\n        return total_loss / self.k\n\n    def _episode(self):\n        super()._episode()\n        # Sample the current head to be used for action selection in this episode\n        self.current_head = random.randrange(self.k)\n\n    def _act_in_training(self, state):\n        self._decay_eps()\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample()\n        else:\n            with torch.no_grad():\n                # Use the current head for action selection during training\n                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n                # Q-values for the current head (1, action_dim)\n                q_values_current_head = self.q_network(state_tensor)[:, self.current_head, :]\n                return q_values_current_head.argmax().item()\n\n    def _act_in_eval(self, state):\n        with torch.no_grad():\n            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n            # In evaluation, average Q-values across all heads for a more robust estimate\n            all_q_values = self.q_network(state_tensor) # (1, k, action_dim)\n            mean_q_values = all_q_values.mean(dim=1).squeeze(0) # (action_dim,)\n            return mean_q_values.argmax().item()\n\n    def _wandb_train_episode_dict(self):\n        log_dict = super()._wandb_train_episode_dict()\n        log_dict[\"train_episode/current_head\"] = self.current_head\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"k\"] = self.k\n        save_dict[\"bernoulli_p\"] = self.bernoulli_p\n        # No need to save self.bernoulli_dist or self.current_head as they are re-initialized/sampled\n        return save_dict","metadata":{"id":"41cf583f","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.543431Z","iopub.execute_input":"2025-06-08T12:14:15.543726Z","iopub.status.idle":"2025-06-08T12:14:15.685187Z","shell.execute_reply.started":"2025-06-08T12:14:15.543703Z","shell.execute_reply":"2025-06-08T12:14:15.684648Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{"id":"891928a5"}},{"cell_type":"markdown","source":"> Paper: [Randomized Prior Functions for Deep Reinforcement Learning](https://arxiv.org/abs/1806.03335)\n\n**25 Points**","metadata":{"id":"d61b3cfe"}},{"cell_type":"markdown","source":"#### Details","metadata":{"id":"d7a70859"}},{"cell_type":"markdown","source":"This method is very similar to Bootstrap DQN, but introduces additional **non-trainable** networks (with multiple heads) called random priors. These priors are added to the Q-network outputs to encourage diversity among ensemble members, both across states and over time. During training, the Q-networks learn to compensate for the effect of these fixed random priors, which helps maintain exploration.\n\n##### Notes\n- Random prior networks are typically smaller (narrower and shallower) than the main Q-networks, so the Q-networks tend to distill their influence during training.\n- There is a $\\delta_\\mathrm{RPF}$ coefficient to control the strength of the random priors, but for simplicity, you can set $\\delta_\\mathrm{RPF}=1$ and omit tuning this hyperparameter.","metadata":{"id":"f887fc72"}},{"cell_type":"markdown","source":"#### Implementation","metadata":{"id":"19df0d41"}},{"cell_type":"code","source":"class PriorMultiHeadQNet(MultiHeadQNet):\n    \"\"\"\n    A shallower multi-head Q-network for the prior in RPF-Bootstrap DQN.\n    This network's weights are fixed after initialization and are not trained.\n    \"\"\"\n    def __init__(self, obs_dim: int, action_dim: int, num_heads: int):\n        # We don't call super().__init__ directly for the feature_extractor\n        # and heads, as we want to define our own shallower versions.\n        # However, we inherit from MultiHeadQNet to reuse its structure\n        # and _initialize_weights method.\n        nn.Module.__init__(self) # Call the base nn.Module constructor\n\n        self.num_heads = num_heads\n\n        # Shared feature extractor - made shallower\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(obs_dim, 128), # Smaller first layer\n            nn.ReLU(),\n            nn.Linear(128, 128),     # Smaller second layer\n            nn.ReLU(),\n        )\n\n        # K independent output heads - mapping from the new feature dimension\n        self.heads = nn.ModuleList([\n            nn.Linear(128, action_dim) for _ in range(num_heads)\n        ])\n\n        self._initialize_weights() # Re-initialize weights for the new architecture\n\n    def _initialize_weights(self):\n        \"\"\"\n        Initialize weights specifically for the shallower prior network.\n        Uses orthogonal initialization for linear layers.\n        \"\"\"\n        for m in self.feature_extractor:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n                if m.bias is not None:\n                    torch.nn.init.constant_(m.bias, 0)\n        for head in self.heads:\n            if isinstance(head, nn.Linear):\n                torch.nn.init.orthogonal_(head.weight) # Default gain for linear\n                if head.bias is not None:\n                    torch.nn.init.constant_(head.bias, 0)\n\n    # The forward method from MultiHeadQNet is directly applicable as the structure is similar.\n    # def forward(self, x: torch.Tensor):\n    #     features = self.feature_extractor(x)\n    #     q_values_per_head = []\n    #     for head in self.heads:\n    #         q_values_per_head.append(head(features))\n    #     return torch.stack(q_values_per_head, dim=1)\n\n\nclass RPFBootstrapDQNAgent(BootstrapDQNAgent):\n    \"\"\"\n    Random Prior Functions (RPF) Bootstrap DQN agent.\n    Incorporates a fixed, randomly initialized prior network.\n    \"\"\"\n\n    def _create_network(self):\n        \"\"\"\n        Creates the main Q-network, target network, and the prior network.\n        The prior network is fixed and not trained.\n        \"\"\"\n        super()._create_network() # Creates self.q_network and self.target_network (MultiHeadQNet)\n\n        # Create the prior network\n        self.prior_network = PriorMultiHeadQNet(\n            self.env.observation_space.shape[0],\n            self.env.action_space.n,\n            self.k\n        ).to(self.device)\n\n        # Freeze the prior network's parameters; they should not be trained\n        for param in self.prior_network.parameters():\n            param.requires_grad = False\n        self.prior_network.eval() # Set prior network to evaluation mode\n\n    def _act_in_training(self, state):\n        \"\"\"\n        Select an action during training using epsilon-greedy strategy.\n        When exploiting, actions are chosen based on Q(s,a) + P(s,a) for the current head.\n        \"\"\"\n        self._decay_eps() # Decay epsilon as per EpsGreedyDQNAgent\n\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample() # Explore\n        else:\n            with torch.no_grad(): # No gradients needed for action selection\n                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n\n                # Get Q-values from the main Q-network for the current head\n                q_values_current_head = self.q_network(state_tensor)[:, self.current_head, :] # (1, action_dim)\n\n                # Get Q-values from the prior network for the current head\n                prior_q_values_current_head = self.prior_network(state_tensor)[:, self.current_head, :] # (1, action_dim)\n\n                # Combine Q-values: Q_effective(s,a) = Q(s,a) + P(s,a)\n                combined_q_values = q_values_current_head + prior_q_values_current_head\n\n                return combined_q_values.argmax().item() # Exploit\n\n    def _act_in_eval(self, state):\n        \"\"\"\n        Select an action during evaluation.\n        Actions are chosen by averaging Q(s,a) + P(s,a) across all heads.\n        \"\"\"\n        with torch.no_grad(): # No gradients needed for evaluation\n            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n\n            # Get Q-values from the main Q-network (1, k, action_dim)\n            all_q_values = self.q_network(state_tensor)\n\n            # Average combined Q-values across all heads for robust evaluation\n            mean_combined_q_values = all_q_values.mean(dim=1).squeeze(0) # (action_dim,)\n\n            return mean_combined_q_values.argmax().item()\n\n    def _compute_loss(self, batch):\n        \"\"\"\n        Compute the loss for the RPF-Bootstrap DQN agent.\n        The Bellman target incorporates the prior network's values.\n        L = SmoothL1Loss( (Q_main(s,a) + P(s,a)), (R + gamma * max_a' (Q_target(s',a') + P(s',a'))) )\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"] # Shape (batch_size, k)\n\n        # 1. Compute current Q-values with prior: Q_main(s,a) + P(s,a)\n        # Q-values from the main Q-network (batch_size, k, action_dim)\n        \n        q_values = self.q_network(states).gather(2, actions.view(-1, 1, 1).expand(-1, self.k, -1)).squeeze()\n    \n        \n        with torch.no_grad(): # Target network and prior network are fixed for target computation\n            \n            \n            all_target_q_values = self.target_network(next_states)\n            \n            \n            all_prior_q_values_next = self.prior_network(next_states)\n\n            \n            target_q_values_per_head_with_prior = all_target_q_values + all_prior_q_values_next # (batch_size, k, action_dim)\n\n            \n            max_next_q_values_action = target_q_values_per_head_with_prior.argmax(dim=2, keepdim=True) # (batch_size, k)\n            final_target_q_values = self.target_network(next_states).gather(2, max_next_q_values_action).squeeze()\n            final_prior_q_values = self.prior_network(next_states).gather(2, max_next_q_values_action).squeeze()\n\n            max_next_q_values_with_prior = final_target_q_values + final_prior_q_values\n            \n            expected_q_values_per_head = rewards.unsqueeze(1) + \\\n                                         (1 - dones.unsqueeze(1)) * self.gamma * max_next_q_values_with_prior # (batch_size, k)\n\n        loss_per_head = nn.SmoothL1Loss(reduction='none')(q_values, expected_q_values_per_head)\n        return (loss_per_head * masks).sum() / masks.sum()\n        ","metadata":{"id":"40007c53","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.685893Z","iopub.execute_input":"2025-06-08T12:14:15.686091Z","iopub.status.idle":"2025-06-08T12:14:15.706911Z","shell.execute_reply.started":"2025-06-08T12:14:15.686068Z","shell.execute_reply":"2025-06-08T12:14:15.706340Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{"id":"607c11f7"}},{"cell_type":"markdown","source":"> Paper: [Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation](https://arxiv.org/abs/2201.01666)\n\n**35 Points**","metadata":{"id":"be50f499"}},{"cell_type":"markdown","source":"#### Details","metadata":{"id":"93657656"}},{"cell_type":"markdown","source":"This method does not explicitly address the exploration problem but focuses on improving sample efficiency.\n\nBy maintaining an ensemble of Q-networks, multiple Q-values can be computed for each state-action pair. This enables the estimation of uncertainty in the target values. Using this uncertainty, a weighted loss is calculated, where the weights are inversely proportional to the uncertainty. The more confident we are about a target, the higher its weight during the update.","metadata":{"id":"b3da71db"}},{"cell_type":"markdown","source":"#### Bonus","metadata":{"id":"01022803"}},{"cell_type":"markdown","source":"1. Use the minimum Effective Batch Size (EBS) as a hyperparameter instead of $\\xi$, and numerically calculate $\\xi$ during each training step based on the minimum EBS. (5 points)\n2. Implement the complete IV-DQN algorithm as described in the appendix of the original paper. (15 points)","metadata":{"id":"c89be494"}},{"cell_type":"markdown","source":"#### Implementation","metadata":{"id":"b329c693"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n# Assuming PriorMultiHeadQNet and RPFBootstrapDQNAgent are defined.\n# For this code to run independently, you'd need their definitions.\n# Let's assume RPFBootstrapDQNAgent provides self.q_network, self.target_network,\n# self.prior_network, self.k, self.gamma, self.delta_rpf (which we'll add to __init__\n# if it's not already there in RPFBootstrapDQNAgent), and super().__init__() works.\n\nclass UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    \"\"\"\n    Uncertainty Estimation (UE) Bootstrap DQN agent, modified to act like Code 1.\n    Weights the loss based on the estimated uncertainty of target values,\n    with head-specific variance calculation and prior scaling.\n    \"\"\"\n\n    def __init__(self, xi: float = 2.0, **kwargs):\n        \"\"\"\n        Args:\n            xi (float): Target minimum Effective Batch Size (1.0 to K).\n        \"\"\"\n\n        super().__init__(**kwargs)\n        self.xi = xi\n        self.latest_min_ebs = float(self.k)\n\n    def _compute_loss(self, batch: dict) -> torch.Tensor:\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"] # Shape (batch_size, k)\n\n        B = states.size(0)\n        k = self.k\n        gamma = self.gamma\n        eps = 1e-6\n\n        \n        q_main_all = self.q_network(states) # (batch_size, k, action_dim)\n        p_all = self.prior_network(states)   # (batch_size, k, action_dim)\n        \n        combined_current = q_main_all + p_all\n\n        a_expanded = actions.unsqueeze(1).expand(-1, k).unsqueeze(2)\n        q_taken = combined_current.gather(dim=2, index=a_expanded).squeeze(2) # (batch_size, k)\n\n        with torch.no_grad():\n\n            q_next_target = self.target_network(next_states)\n            q_next_prior = self.prior_network(next_states)\n            q_next = q_next_target + q_next_prior # (batch_size, k, action_dim)\n\n            max_combined_next, _ = torch.max(q_next, dim=2)\n\n            variances = torch.var(max_combined_next, dim=1)\n\n            variances_detach = variances.detach()\n            \n            low, high = 0.0, 10.0\n    \n            for _ in range(30):\n                mid = (low + high) / 2.0\n                weights = 1.0 / (variances_detach + mid)\n                curr_ebs = torch.sum(weights)**2 / torch.sum(weights**2)\n                if curr_ebs <= self.xi:\n                    high = mid\n                else:\n                    low = mid\n            \n            weights = 1.0 / (variances + (low + high) / 2.0)\n            self.latest_min_ebs = (weights.sum() ** 2 / weights.pow(2).sum()).item()\n\n            best_actions = q_next.argmax(dim=2, keepdim=True)  # (B, K, 1)\n\n            q_target_selected = self.target_network(next_states).gather(2, best_actions).squeeze()\n            q_prior_selected = self.prior_network(next_states).gather(2, best_actions).squeeze()\n            q_combined = q_target_selected + q_prior_selected  # (B, K)\n\n            expected_q = rewards.unsqueeze(1) + (1 - dones.unsqueeze(1)) * self.gamma * q_combined\n\n        q_current = self.q_network(states).gather(2, actions.view(-1, 1, 1).expand(-1, self.k, -1)).squeeze()\n        raw_loss = nn.SmoothL1Loss(reduction='none')(q_current, expected_q)  # (B, K)\n\n        weighted_loss = raw_loss * weights.unsqueeze(1)  # (B, K)\n        masked_loss = weighted_loss * masks\n\n        return masked_loss.sum() / masks.sum()\n\n    def _save_dict(self) -> dict:\n        \"\"\"\n        Add 'xi'parameter to the saved dictionary.\n        \"\"\"\n        save_dict = super()._save_dict()\n        save_dict[\"xi\"] = self.xi\n        return save_dict\n\n    def _wandb_train_step_dict(self) -> dict:\n        \"\"\"\n        \"\"\"\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"train_step/latest_min_ebs\"] = self.latest_min_ebs\n        return log_dict","metadata":{"id":"562c87c2","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.707640Z","iopub.execute_input":"2025-06-08T12:14:15.707881Z","iopub.status.idle":"2025-06-08T12:14:15.726863Z","shell.execute_reply.started":"2025-06-08T12:14:15.707858Z","shell.execute_reply":"2025-06-08T12:14:15.726217Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## âš™ï¸ Configs","metadata":{"id":"d23f4978"}},{"cell_type":"markdown","source":"Feel free to change hyperparameters","metadata":{"id":"2688b46e"}},{"cell_type":"code","source":"env = [\"FrozenLake\", \"CartPole\", \"MountainCar\", \"SeaQuest\", \"LunarLander\"][2]\nprint(f\"{env} is selected.\")\n\nbase_agent_config = {\n    **ENVS[env][\"env\"],\n    \"default_batch_size\": 128,\n    \"gamma\": 0.995,\n    \"learning_rate\": 3e-4,\n    \"replay_buffer_capacity\":200_000,\n    \"tau\": 5e-3,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"gradient_norm_clip\": 10.0,\n    \"start_training_after\": 10000,\n    \"normalize_rewards\": False,\n    \"scale_rewards\": None\n}\n\nbase_run_config = {\n    **ENVS[env][\"run\"],\n    \"learn_every\": 1,  # Apply learning every n steps of rollout\n    \"eval_every\": 10_000,  # Evaluate model approximately every n steps\n}","metadata":{"id":"52b305aa","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.727572Z","iopub.execute_input":"2025-06-08T12:14:15.727855Z","iopub.status.idle":"2025-06-08T12:14:15.744289Z","shell.execute_reply.started":"2025-06-08T12:14:15.727836Z","shell.execute_reply":"2025-06-08T12:14:15.743580Z"}},"outputs":[{"name":"stdout","text":"MountainCar is selected.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\neps_greedy_config = {\n    **base_agent_config,\n    \"eps_decay\": 0.99996,\n    \"eps_min\": 0.01,\n    \"epsilon\": 1.0,\n}","metadata":{"id":"e87edb5f","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.745000Z","iopub.execute_input":"2025-06-08T12:14:15.745210Z","iopub.status.idle":"2025-06-08T12:14:15.761422Z","shell.execute_reply.started":"2025-06-08T12:14:15.745167Z","shell.execute_reply":"2025-06-08T12:14:15.760818Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"bootstrap_dqn_config = {\n    **eps_greedy_config,\n    \"k\": 10,\n    \"bernoulli_p\": 0.5\n}","metadata":{"id":"f5b970af","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.762108Z","iopub.execute_input":"2025-06-08T12:14:15.762416Z","iopub.status.idle":"2025-06-08T12:14:15.775775Z","shell.execute_reply.started":"2025-06-08T12:14:15.762388Z","shell.execute_reply":"2025-06-08T12:14:15.775145Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"rpf_bootstrap_dqn_config = {\n    **bootstrap_dqn_config,\n}","metadata":{"id":"bdc49176","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.776455Z","iopub.execute_input":"2025-06-08T12:14:15.776699Z","iopub.status.idle":"2025-06-08T12:14:15.789911Z","shell.execute_reply.started":"2025-06-08T12:14:15.776675Z","shell.execute_reply":"2025-06-08T12:14:15.789296Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"ue_bootstrap_dqn_config = {\n    **rpf_bootstrap_dqn_config,\n    \"xi\": 0.2\n}","metadata":{"id":"af2c58a0","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.790523Z","iopub.execute_input":"2025-06-08T12:14:15.790692Z","iopub.status.idle":"2025-06-08T12:14:15.803772Z","shell.execute_reply.started":"2025-06-08T12:14:15.790679Z","shell.execute_reply":"2025-06-08T12:14:15.803053Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## ğŸ”„ Training","metadata":{"id":"b1b9e105"}},{"cell_type":"markdown","source":"The `try-except` block allows you to terminate the current algorithm's run directly from the W&B panel and proceed to the next algorithm without crashing the entire notebook. This can be particularly useful when using Kaggle's *Save Version* feature.","metadata":{"id":"b5807e81"}},{"cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{"id":"8c06ec09"}},{"cell_type":"code","source":"# # DON'T CHANGE THIS BLOCK\n# wandb_config = {\n#     \"project\": PROJECT_NAME,\n#     \"name\": f\"eps_greedy {env}\",\n#     \"config\": {**eps_greedy_config, **base_run_config, \"machine\": get_machine()},\n#     \"save_code\": SAVE_CODE,\n#     \"tags\": [\"dqn\", \"eps_greedy\"],\n# }\n\n# if DEBUG:\n#     wandb_run = None\n# else:\n#     wandb_run = wandb.init(**wandb_config)\n\n# eps_greedy_dqn_agent = EpsGreedyDQNAgent(wandb_run=wandb_run, **eps_greedy_config)","metadata":{"id":"10511385","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.804511Z","iopub.execute_input":"2025-06-08T12:14:15.804701Z","iopub.status.idle":"2025-06-08T12:14:15.816970Z","shell.execute_reply.started":"2025-06-08T12:14:15.804686Z","shell.execute_reply":"2025-06-08T12:14:15.816482Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# # DON'T CHANGE THIS BLOCK\n# try:\n#     eps_greedy_dqn_agent.train(**base_run_config)\n#     wandb_run.finish()\n# except KeyboardInterrupt:\n#     pass","metadata":{"id":"d97f9c74","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.817671Z","iopub.execute_input":"2025-06-08T12:14:15.817900Z","iopub.status.idle":"2025-06-08T12:14:15.832545Z","shell.execute_reply.started":"2025-06-08T12:14:15.817886Z","shell.execute_reply":"2025-06-08T12:14:15.831914Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### Bootstrap DQN","metadata":{"id":"98e76b66"}},{"cell_type":"code","source":"# # DON'T CHANGE THIS BLOCK\n# wandb_config = {\n#     \"project\": PROJECT_NAME,\n#     \"name\": f\"bootstrap {env}\",\n#     \"save_code\": SAVE_CODE,\n#     \"tags\": [\"dqn\", \"bootstrap\"],\n# }\n\n# wandb_config[\"config\"] = {} if TA else {**bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n# DEBUG = False\n# if DEBUG:\n#     wandb_run = None\n# else:\n#     wandb_run = wandb.init(**wandb_config)\n\n# bootstrap_dqn_agent = BootstrapDQNAgent(wandb_run=wandb_run, **bootstrap_dqn_config)","metadata":{"id":"16c2ee29","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.835391Z","iopub.execute_input":"2025-06-08T12:14:15.835607Z","iopub.status.idle":"2025-06-08T12:14:15.847241Z","shell.execute_reply.started":"2025-06-08T12:14:15.835593Z","shell.execute_reply":"2025-06-08T12:14:15.846675Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# # DON'T CHANGE THIS BLOCK\n# try:\n#     bootstrap_dqn_agent.train(**base_run_config)\n#     wandb_run.finish()\n# except KeyboardInterrupt:\n#     pass","metadata":{"id":"a6cc270f","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.848040Z","iopub.execute_input":"2025-06-08T12:14:15.848661Z","iopub.status.idle":"2025-06-08T12:14:15.865654Z","shell.execute_reply.started":"2025-06-08T12:14:15.848645Z","shell.execute_reply":"2025-06-08T12:14:15.864935Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{"id":"201d00bc"}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": f\"randomized_prior {env}\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"rpf_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**rpf_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nrpf_bootstrap_dqn_agent = RPFBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)","metadata":{"id":"8141fbab","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:15.866385Z","iopub.execute_input":"2025-06-08T12:14:15.866565Z","iopub.status.idle":"2025-06-08T12:14:36.435776Z","shell.execute_reply.started":"2025-06-08T12:14:15.866551Z","shell.execute_reply":"2025-06-08T12:14:36.435126Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohamadahmadpour1383\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250608_121421-4poggq2y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/4poggq2y' target=\"_blank\">randomized_prior MountainCar</a></strong> to <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/4poggq2y' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/4poggq2y</a>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    rpf_bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass\n\n### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{"id":"6ace832a","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T12:14:36.436706Z","iopub.execute_input":"2025-06-08T12:14:36.436926Z","iopub.status.idle":"2025-06-08T13:16:43.529359Z","shell.execute_reply.started":"2025-06-08T12:14:36.436906Z","shell.execute_reply":"2025-06-08T13:16:43.528668Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\nerror: XDG_RUNTIME_DIR not set in the environment.\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","output_type":"stream"},{"name":"stdout","text":"Trained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>â–ˆâ–ˆâ–ˆâ–â–…â–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–„â–ˆâ–†â–ˆâ–ˆâ–†â–ˆâ–„â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval_episode/mean_reward</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>eval_episode/sum_reward</td><td>â–â–â–â–ˆâ–„â–ƒâ–â–â–‚â–â–â–â–‚â–â–â–…â–â–ƒâ–â–â–ƒâ–â–…â–†â–â–â–â–â–â–</td></tr><tr><td>train_episode/current_head</td><td>â–‡â–ƒâ–ƒâ–„â–ˆâ–†â–…â–ƒâ–†â–â–†â–‡â–â–…â–ƒâ–‚â–ƒâ–†â–†â–†â–ˆâ–â–„â–…â–ƒâ–ˆâ–â–„â–‡â–ˆâ–â–‚â–…â–ˆâ–‡â–ˆâ–‡â–ˆâ–‚â–†</td></tr><tr><td>train_episode/episode_length</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–…â–„â–„â–ˆâ–ˆâ–…â–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–…â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–‡â–ˆâ–â–ˆâ–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>train_episode/mean_loss</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–ˆ</td></tr><tr><td>train_episode/mean_return</td><td>â–â–â–â–â–â–…â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_episode/mean_reward</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_episode/sum_loss</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–„â–…â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>train_episode/sum_reward</td><td>â–â–â–â–„â–â–†â–ˆâ–â–â–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–†â–‚â–â–â–‚â–â–â–â–â–†â–†â–†â–</td></tr><tr><td>train_episode/var_return</td><td>â–â–â–â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train_step/epsilon</td><td>â–ˆâ–ˆâ–…â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_step/grad_norm</td><td>â–â–â–â–‚â–‚â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_step/loss</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–„â–â–â–â–â–â–ƒâ–ˆâ–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>200</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-200</td></tr><tr><td>train_episode/current_head</td><td>4</td></tr><tr><td>train_episode/episode_length</td><td>119</td></tr><tr><td>train_episode/mean_loss</td><td>2021.63389</td></tr><tr><td>train_episode/mean_return</td><td>-119.93597</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>240574.43243</td></tr><tr><td>train_episode/sum_reward</td><td>-119</td></tr><tr><td>train_episode/var_return</td><td>130.32822</td></tr><tr><td>train_step/epsilon</td><td>0.01</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>2920.17896</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">randomized_prior MountainCar</strong> at: <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/4poggq2y' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/4poggq2y</a><br> View project at: <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250608_121421-4poggq2y/logs</code>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"\n# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": f\"uncertainty_estimation {env}\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **ue_bootstrap_dqn_config)","metadata":{"id":"eb4efd0c","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T13:18:06.592364Z","iopub.execute_input":"2025-06-08T13:18:06.593001Z","iopub.status.idle":"2025-06-08T13:18:17.939564Z","shell.execute_reply.started":"2025-06-08T13:18:06.592980Z","shell.execute_reply":"2025-06-08T13:18:17.938785Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250608_131806-slzaoqqb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/slzaoqqb' target=\"_blank\">uncertainty_estimation MountainCar</a></strong> to <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/slzaoqqb' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/slzaoqqb</a>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nue_bootstrap_dqn_agent.train(**base_run_config)\nwandb_run.finish()","metadata":{"id":"f8f8b718","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T13:18:17.940665Z","iopub.execute_input":"2025-06-08T13:18:17.940902Z","iopub.status.idle":"2025-06-08T14:43:17.097550Z","shell.execute_reply.started":"2025-06-08T13:18:17.940874Z","shell.execute_reply":"2025-06-08T14:43:17.096834Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1315947884.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1315947884.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","output_type":"stream"},{"name":"stdout","text":"Trained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>â–ˆâ–ˆâ–ˆâ–‚â–†â–‚â–ƒâ–„â–â–…â–†â–†â–â–â–â–‚â–‚â–…â–…â–…â–…â–†â–…â–â–†â–‡â–†â–â–…â–†</td></tr><tr><td>eval_episode/mean_reward</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>eval_episode/sum_reward</td><td>â–â–â–â–‡â–ƒâ–‡â–†â–…â–ˆâ–„â–ƒâ–ƒâ–ˆâ–ˆâ–ˆâ–‡â–‡â–„â–„â–„â–„â–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–ˆâ–„â–ƒ</td></tr><tr><td>train_episode/current_head</td><td>â–…â–…â–„â–†â–…â–‚â–ˆâ–…â–…â–‡â–…â–„â–„â–…â–ƒâ–â–…â–ƒâ–„â–â–„â–‡â–ˆâ–‚â–‡â–ƒâ–…â–‡â–ˆâ–…â–„â–„â–‚â–â–â–„â–†â–…â–ˆâ–</td></tr><tr><td>train_episode/episode_length</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–…â–…â–„â–…â–†â–…â–â–‚â–…â–…â–…â–â–…â–â–…â–…â–‚â–…â–‚â–â–†â–â–â–…â–†â–…â–…â–†â–‚â–â–…â–â–…â–‚</td></tr><tr><td>train_episode/mean_loss</td><td>â–â–â–…â–…â–„â–…â–ˆâ–‡â–„â–…â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_episode/mean_return</td><td>â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_episode/mean_reward</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_episode/sum_loss</td><td>â–â–‚â–†â–‡â–‡â–†â–ˆâ–†â–…â–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_episode/sum_reward</td><td>â–â–â–â–ƒâ–ƒâ–ƒâ–„â–â–„â–„â–â–â–ƒâ–ˆâ–„â–„â–†â–ƒâ–„â–ˆâ–ˆâ–ˆâ–„â–„â–„â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–„â–„â–‡â–ˆ</td></tr><tr><td>train_episode/var_return</td><td>â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_step/epsilon</td><td>â–ˆâ–‡â–†â–†â–…â–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_step/grad_norm</td><td>â–â–â–â–â–â–‚â–„â–ƒâ–ˆâ–†â–†â–‚â–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_step/latest_min_ebs</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–…â–„â–„â–…â–…â–…â–…â–…â–†</td></tr><tr><td>train_step/loss</td><td>â–â–†â–‚â–…â–ˆâ–„â–„â–„â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>162</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-162</td></tr><tr><td>train_episode/current_head</td><td>3</td></tr><tr><td>train_episode/episode_length</td><td>20</td></tr><tr><td>train_episode/mean_loss</td><td>2e-05</td></tr><tr><td>train_episode/mean_return</td><td>-100.13332</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>0.00033</td></tr><tr><td>train_episode/sum_reward</td><td>-20</td></tr><tr><td>train_episode/var_return</td><td>355.3989</td></tr><tr><td>train_step/epsilon</td><td>0.01</td></tr><tr><td>train_step/grad_norm</td><td>8e-05</td></tr><tr><td>train_step/latest_min_ebs</td><td>107.34478</td></tr><tr><td>train_step/loss</td><td>3e-05</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">uncertainty_estimation MountainCar</strong> at: <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/slzaoqqb' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW/runs/slzaoqqb</a><br> View project at: <a href='https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/mohamadahmadpour1383/Mohammadjavad-Ahmadpour-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250608_131806-slzaoqqb/logs</code>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}